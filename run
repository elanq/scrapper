#!/usr/bin/env ruby

require 'httparty'
require 'pry'
require 'prawn'

links = ARGV
threads = []
user_replies = []
line = 50.times.map{ "#" }.join + "\n"
link_validation = /\b(reddit.com\/r\/|comments\/)/

# scrap data from given reddit urls
links.each do |link|
  if link.scan(link_validation).size
    response = HTTParty.get(link)
    # only handle successful request
    if response.ok? || response.success?
      json_response = JSON.parse(response.body, symbolize_names: true)
      # first response is always thread starter
      thread = json_response.first[:data][:children].first
      # we only need the thread replies for this case
      replies = json_response.last[:data][:children]

      # iterate reply of users. put them into map
      replies.each do |reply|
        next if reply[:data][:author].nil?
        reply_data = reply[:data]
        data = {
          author: reply_data[:author],
          body: reply_data[:body],
          body_html: reply_data[:body_html],
          ups: reply_data[:ups] || 0
        }
        user_replies.push(data)
      end

      # sort by number of upvote
      user_replies.sort_by{|r| r[:ups]}.reverse!

      # set thread data
      title = thread[:data][:title][0..30].gsub(/\s\w+\s*$/, '...')
      thread_data = {
        thread_name: thread[:data][:title],
        data: user_replies,
        filename: "#{thread[:data][:author]}-#{title}.pdf"
      }
      threads.push(thread_data)
    end
  end
end

# generate each link into pdf file
threads.each do |t|
  Prawn::Document.generate(t[:filename]) do
    t[:data].each do |reply|
      text "Author : #{reply[:author]} \n"
      text "#{reply[:body]} \n"
      text line
    end
  end
  puts "#{t[:filename]} successfully generated"
end
